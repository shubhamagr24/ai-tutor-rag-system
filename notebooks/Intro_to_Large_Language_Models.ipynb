{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the specific version of the openai library used in this lesson Because We pin\n",
        "# the version to ensure the code works exactly as shown, as library updates can sometimes\n",
        "# introduce changes.\n",
        "\n",
        "# The '-q' flag makes the installation quieter (less output)\n",
        "!pip install -q openai==1.59.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eiqwUbfcShuQ",
        "outputId": "669687a6-8723-473d-ecfa-b8f34e55efd0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/455.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/455.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.6/455.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCoxlgoCSD2P",
        "outputId": "d5b6ec41-1811-4ffd-dcbb-f31c5bee233c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key loaded from Colab userdata.\n",
            "API Key loaded successfully (starting with: sk-p...).\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "try:\n",
        "    # Try to get API key from Google Colab's userdata\n",
        "    # Make sure to replace 'OPENAI_API_KEY1' with the actual name you gave your secret key in Google Colab secrets.\n",
        "    api_key = userdata.get('OPENAI_API_KEY1')\n",
        "    if api_key:\n",
        "        print(\"API key loaded from Colab userdata.\")\n",
        "\n",
        "    if not api_key:\n",
        "        print(\"OpenAI API key not found in Colab secrets.\")\n",
        "        api_key = input(\"Please enter your OpenAI API key manually: \")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Not running in Colab environment.\")\n",
        "    api_key = input(\"Please enter your OpenAI API key manually: \")\n",
        "\n",
        "# Final validation\n",
        "if not api_key:\n",
        "    raise ValueError(\"API Key not provided. Please ensure it's set.\")\n",
        "else:\n",
        "    print(f\"API Key loaded successfully (starting with: {api_key[:4]}...).\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All subsequent API calls will be made through this 'client' object.\n",
        "try:\n",
        "    client = openai.OpenAI(api_key=api_key)\n",
        "    print(\"OpenAI client initialized successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing OpenAI client: {e}\")\n",
        "    # You might want to exit or raise the error here depending on desired behavior\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCTwrKEOTEc1",
        "outputId": "685be879-ac78-4411-bc1c-f2fd1ad073d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 2: First Turn - Asking the Initial Question ---\n",
        "print(\"\\n--- Starting Conversation: Turn 1 ---\")\n",
        "\n",
        "# Define the system message (persona) for the AI Tutor\n",
        "system_message = {\"role\": \"system\", \"content\": \"You are a helpful AI Tutor explaining Large Language Model concepts simply.\"}\n",
        "\n",
        "# Define the user's first question\n",
        "user_message_1 = {\"role\": \"user\", \"content\": \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}\n",
        "\n",
        "# Create the messages list for the *first* API call\n",
        "messages_history = [\n",
        "    system_message,\n",
        "    user_message_1\n",
        "]\n",
        "\n",
        "print(f\"Sending messages: {messages_history}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQwTVEM3TFeL",
        "outputId": "f93fa06f-dc0e-4516-e1c6-2344df39c2d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Conversation: Turn 1 ---\n",
            "Sending messages: [{'role': 'system', 'content': 'You are a helpful AI Tutor explaining Large Language Model concepts simply.'}, {'role': 'user', 'content': \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for this call\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "TEMPERATURE = 0.5\n",
        "MAX_TOKENS = 150\n",
        "SEED = 123\n",
        "\n",
        "try:\n",
        "    print(f\"\\nMaking API call to {MODEL}...\")\n",
        "    # Use the client object's method to create a chat completion\n",
        "    completion_1 = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages_history,\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        seed=SEED\n",
        "    )\n",
        "    print(\"API call successful.\")\n",
        "\n",
        "    # --- Process the response from the first turn ---\n",
        "    # Extract the assistant's reply content\n",
        "    assistant_response_1 = completion_1.choices[0].message.content\n",
        "    # Extract the full message object to add to history later\n",
        "    assistant_message_1 = completion_1.choices[0].message\n",
        "\n",
        "    print(\"\\nAI Tutor (Turn 1):\")\n",
        "    print(assistant_response_1)\n",
        "\n",
        "    # Print token usage for this call\n",
        "    usage_1 = completion_1.usage\n",
        "    print(f\"\\nToken Usage (Turn 1): Prompt={usage_1.prompt_tokens}, Completion={usage_1.completion_tokens}, Total={usage_1.total_tokens}\")\n",
        "    finish_reason_1 = completion_1.choices[0].finish_reason\n",
        "    print(f\"Finish Reason: {finish_reason_1}\")\n",
        "\n",
        "except openai.APIError as e:\n",
        "    # Handle API errors (e.g., server issues, rate limits)\n",
        "    print(f\"OpenAI API returned an API Error: {e}\")\n",
        "except openai.AuthenticationError as e:\n",
        "    # Handle Authentication errors (e.g., invalid API key)\n",
        "    print(f\"OpenAI Authentication Error: {e}\")\n",
        "except Exception as e:\n",
        "    # Handle other potential errors\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rCEBIxfWHrX",
        "outputId": "5b54b200-5224-4802-ff37-56520387e7c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Making API call to gpt-4o-mini...\n",
            "API call successful.\n",
            "\n",
            "AI Tutor (Turn 1):\n",
            "Sure! In the context of Large Language Models (LLMs), a \"token\" is a basic unit of text that the model processes. Tokens can be words, parts of words, or even punctuation marks. \n",
            "\n",
            "Think of it this way: when you read a sentence, you break it down into smaller pieces to understand it better. Similarly, LLMs break down text into tokens to analyze and generate language.\n",
            "\n",
            "For example, the sentence \"I love apples!\" might be broken down into the following tokens:\n",
            "- \"I\"\n",
            "- \"love\"\n",
            "- \"apples\"\n",
            "- \"!\"\n",
            "\n",
            "In some cases, a token might represent just a part of a word, especially for longer or complex words. For instance, the word \"unhappiness\"\n",
            "\n",
            "Token Usage (Turn 1): Prompt=46, Completion=150, Total=196\n",
            "Finish Reason: length\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 3: Second Turn - Asking a Follow-up Question ---\n",
        "print(\"\\n--- Continuing Conversation: Turn 2 ---\")\n",
        "\n",
        "# Assume the first turn was successful and we have 'assistant_message_1'\n",
        "# Define the user's second question, referencing the previous explanation\n",
        "user_message_2 = {\"role\": \"user\", \"content\": \"Thanks! So, based on your explanation, are common words like 'the' or 'is' usually single tokens?\"}\n",
        "\n",
        "# --- CRITICAL STEP: Update the message history ---\n",
        "# Append the assistant's *previous* response to the history\n",
        "messages_history.append(assistant_message_1)\n",
        "# Append the user's *new* question to the history\n",
        "messages_history.append(user_message_2)\n",
        "\n",
        "print(f\"\\nSending updated messages: {messages_history}\") # Notice how the list has grown\n",
        "\n",
        "# Parameters for the second call (could be the same or different)\n",
        "# Let's make it slightly more deterministic for a factual answer\n",
        "TEMPERATURE_2 = 0.2\n",
        "MAX_TOKENS_2 = 100\n",
        "# Using the same seed ensures the *entire conversation flow* is reproducible if inputs are identical\n",
        "SEED_2 = 123\n",
        "\n",
        "try:\n",
        "    print(f\"\\nMaking API call to {MODEL} (Turn 2)...\")\n",
        "    completion_2 = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages_history, # Send the *full* history\n",
        "        temperature=TEMPERATURE_2,\n",
        "        max_tokens=MAX_TOKENS_2,\n",
        "        seed=SEED_2\n",
        "    )\n",
        "    print(\"API call successful.\")\n",
        "\n",
        "    # --- Process the response from the second turn ---\n",
        "    assistant_response_2 = completion_2.choices[0].message.content\n",
        "    # We don't strictly need to save assistant_message_2 unless continuing the conversation\n",
        "\n",
        "    print(\"\\nAI Tutor (Turn 2):\")\n",
        "    print(assistant_response_2)\n",
        "\n",
        "    # Print token usage for this call\n",
        "    usage_2 = completion_2.usage\n",
        "    print(f\"\\nToken Usage (Turn 2): Prompt={usage_2.prompt_tokens}, Completion={usage_2.completion_tokens}, Total={usage_2.total_tokens}\")\n",
        "    # Note: prompt_tokens for turn 2 will be larger as it includes the history from turn 1.\n",
        "    finish_reason_2 = completion_2.choices[0].finish_reason\n",
        "    print(f\"Finish Reason: {finish_reason_2}\")\n",
        "\n",
        "except openai.APIError as e:\n",
        "    print(f\"OpenAI API returned an API Error: {e}\")\n",
        "except openai.AuthenticationError as e:\n",
        "    print(f\"OpenAI Authentication Error: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkzqFe8BWJHc",
        "outputId": "77f7e304-d2f1-4c06-e6bb-c3fb5f57a154"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Continuing Conversation: Turn 2 ---\n",
            "\n",
            "Sending updated messages: [{'role': 'system', 'content': 'You are a helpful AI Tutor explaining Large Language Model concepts simply.'}, {'role': 'user', 'content': \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}, ChatCompletionMessage(content='Sure! In the context of Large Language Models (LLMs), a \"token\" is a basic unit of text that the model processes. Tokens can be words, parts of words, or even punctuation marks. \\n\\nThink of it this way: when you read a sentence, you break it down into smaller pieces to understand it better. Similarly, LLMs break down text into tokens to analyze and generate language.\\n\\nFor example, the sentence \"I love apples!\" might be broken down into the following tokens:\\n- \"I\"\\n- \"love\"\\n- \"apples\"\\n- \"!\"\\n\\nIn some cases, a token might represent just a part of a word, especially for longer or complex words. For instance, the word \"unhappiness\"', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]), {'role': 'user', 'content': \"Thanks! So, based on your explanation, are common words like 'the' or 'is' usually single tokens?\"}]\n",
            "\n",
            "Making API call to gpt-4o-mini (Turn 2)...\n",
            "API call successful.\n",
            "\n",
            "AI Tutor (Turn 2):\n",
            "Yes, that's correct! Common words like \"the,\" \"is,\" \"and,\" and other short, frequently used words are typically represented as single tokens in most tokenization systems. These words are so common that they are often treated as individual units, making it easier for the model to understand and generate text.\n",
            "\n",
            "However, the exact way tokens are defined can vary depending on the specific tokenization method used by the language model. Some models might break down longer or less common words into multiple tokens, but\n",
            "\n",
            "Token Usage (Turn 2): Prompt=228, Completion=100, Total=328\n",
            "Finish Reason: length\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example usage object from completion_1 or completion_2:\n",
        "print(usage_1.prompt_tokens)  # -> number of input tokens\n",
        "print(usage_1.completion_tokens) # -> number of output tokens\n",
        "print(usage_1.total_tokens) # -> sum of both"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFh2GfScWT-N",
        "outputId": "3618ec21-ecc5-4fa3-8e22-0dbac3d6b314"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n",
            "150\n",
            "196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 4: Cost Calculation Function & Example ---\n",
        "\n",
        "def calculate_cost(usage, input_price_per_mil, output_price_per_mil):\n",
        "    \"\"\"Calculates the cost of an API call based on token usage and prices.\n",
        "\n",
        "    Args:\n",
        "        usage: The usage object from the OpenAI completion response\n",
        "               (e.g., completion.usage). It should have attributes\n",
        "               'prompt_tokens' and 'completion_tokens'.\n",
        "        input_price_per_mil: Cost in USD per 1 million input tokens.\n",
        "        output_price_per_mil: Cost in USD per 1 million output tokens.\n",
        "\n",
        "    Returns:\n",
        "        The total cost in USD for the API call, or None if usage is invalid.\n",
        "    \"\"\"\n",
        "    if not usage or not hasattr(usage, 'prompt_tokens') or not hasattr(usage, 'completion_tokens'):\n",
        "        print(\"Warning: Invalid usage object provided for cost calculation.\")\n",
        "        return None\n",
        "\n",
        "    input_cost = (usage.prompt_tokens / 1_000_000) * input_price_per_mil\n",
        "    output_cost = (usage.completion_tokens / 1_000_000) * output_price_per_mil\n",
        "    total_cost = input_cost + output_cost\n",
        "    return total_cost\n",
        "\n",
        "# --- Current Prices (April 2025) for GPT-4o-mini ---\n",
        "# IMPORTANT: Always verify at https://openai.com/pricing\n",
        "PRICE_INPUT_PER_MIL = 0.60\n",
        "PRICE_OUTPUT_PER_MIL = 2.40\n",
        "\n",
        "print(f\"\\n--- Cost Calculations (GPT-4o-mini, April 2025 Rates) ---\")\n",
        "print(f\"Prices: Input=${PRICE_INPUT_PER_MIL:.2f}/1M, Output=${PRICE_OUTPUT_PER_MIL:.2f}/1M\")\n",
        "\n",
        "# Calculate cost for Turn 1 (assuming completion_1 and usage_1 exist from Block 2)\n",
        "try:\n",
        "    if 'usage_1' in locals(): # Check if usage_1 variable exists\n",
        "         cost_1 = calculate_cost(usage_1, PRICE_INPUT_PER_MIL, PRICE_OUTPUT_PER_MIL)\n",
        "         if cost_1 is not None:\n",
        "              print(f\"\\nCost for Turn 1:\")\n",
        "              print(f\"  Prompt Tokens: {usage_1.prompt_tokens}, Completion Tokens: {usage_1.completion_tokens}\")\n",
        "              print(f\"  Total Cost: ${cost_1:.8f}\")\n",
        "    else:\n",
        "         print(\"\\nSkipping Turn 1 cost calculation (usage_1 not found).\")\n",
        "\n",
        "    # Calculate cost for Turn 2 (assuming completion_2 and usage_2 exist from Block 3)\n",
        "    if 'usage_2' in locals(): # Check if usage_2 variable exists\n",
        "        cost_2 = calculate_cost(usage_2, PRICE_INPUT_PER_MIL, PRICE_OUTPUT_PER_MIL)\n",
        "        if cost_2 is not None:\n",
        "            print(f\"\\nCost for Turn 2:\")\n",
        "            print(f\"  Prompt Tokens: {usage_2.prompt_tokens}, Completion Tokens: {usage_2.completion_tokens}\")\n",
        "            print(f\"  Total Cost: ${cost_2:.8f}\")\n",
        "    else:\n",
        "         print(\"\\nSkipping Turn 2 cost calculation (usage_2 not found).\")\n",
        "\n",
        "    # Calculate total conversation cost\n",
        "    if 'cost_1' in locals() and 'cost_2' in locals() and cost_1 is not None and cost_2 is not None:\n",
        "        total_conversation_cost = cost_1 + cost_2\n",
        "        print(f\"\\nTotal Conversation Cost (Turn 1 + Turn 2): ${total_conversation_cost:.8f}\")\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"\\nCould not calculate costs, a required variable is missing: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during cost calculation: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "217IT8sKWoAK",
        "outputId": "4320e2e8-252b-4ea9-fe00-946979096e61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cost Calculations (GPT-4o-mini, April 2025 Rates) ---\n",
            "Prices: Input=$0.60/1M, Output=$2.40/1M\n",
            "\n",
            "Cost for Turn 1:\n",
            "  Prompt Tokens: 46, Completion Tokens: 150\n",
            "  Total Cost: $0.00038760\n",
            "\n",
            "Cost for Turn 2:\n",
            "  Prompt Tokens: 228, Completion Tokens: 100\n",
            "  Total Cost: $0.00037680\n",
            "\n",
            "Total Conversation Cost (Turn 1 + Turn 2): $0.00076440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzk2VbYfW8sx"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}